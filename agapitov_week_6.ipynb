{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование с помощью регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем список регионов для которых будем строить прогноз и загружаем аггрегированные по часам данные для этих регионов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = [1075, 1076, 1077, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1172, 1173, 1174, 1175, 1176, 1177,\n",
    "               1178, 1179, 1180, 1181, 1182, 1183, 1184, 1221, 1222, 1223, 1224, 1225, 1227, 1228, 1229, 1230, 1231,\n",
    "               1232, 1233, 1234, 1235, 1272, 1273, 1274, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287,\n",
    "               1326, 1327, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1376, 1377, 1378, 1380, 1382, 1383,\n",
    "               1384, 1385, 1386, 1387, 1388, 1389, 1390, 1426, 1431, 1434, 1435, 1436, 1437, 1438, 1439, 1441, 1442,\n",
    "               1480, 1482, 1483, 1530, 1532, 1533, 1580, 1630, 1684, 1733, 1734, 1783, 2068, 2069, 2118, 2119, 2168]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите обучающие выборки прошлой недели, перечислите используемые в моделях признаки и посчитайте Q_{may}Q \n",
    "may  — качество прогнозов моделей, настроенных на данных до апреля 2016, в мае 2016.\n",
    "\n",
    "Я не сохранил сами модели поэтому повторяю расчёт прошлой недели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('regions_counts_by_hours.csv', index_col=0)\n",
    "data.datetime = data.datetime.map(lambda x: pd.to_datetime(x))\n",
    "\n",
    "train_from = pd.to_datetime('2016-02-01 00:00:00')\n",
    "train_to = pd.to_datetime('2016-04-30 17:00:00')\n",
    "\n",
    "test_from = pd.to_datetime('2016-04-30 23:00:00')\n",
    "test_to = pd.to_datetime('2016-05-31 17:00:00')\n",
    "\n",
    "X_fields = {'count', 'region', 'day', 'month', 'weekday', 'hour', 'sum_p_12_h', 'sum_p_24_h', 'sum_p_w'}\n",
    "y_fields = set()\n",
    "values = pd.DataFrame()\n",
    "\n",
    "for region in region_list:\n",
    "    value = pd.DataFrame()\n",
    "    reg = str(region)\n",
    "    value['count'] = data[reg]\n",
    "    value['region'] = [region] * data.shape[0]\n",
    "    value['datetime'] = data['datetime']\n",
    "\n",
    "    # Добавляем признаки дня, месяца, дня недели и часа. Поскольку у меня данные за 1 год, то признак года добавлять смысла нет.\n",
    "    value['day'] = data.datetime.map(lambda x: x.day)\n",
    "    value['month'] = data.datetime.map(lambda x: x.month)\n",
    "    value['weekday'] = data.datetime.map(lambda x: x.weekday())\n",
    "    value['hour'] = data.datetime.map(lambda x: x.hour)\n",
    "\n",
    "    # Добавляем признаки числа поездок из этого региона за прошлые часы и дни\n",
    "    for i in xrange(1, 24):\n",
    "        value['ph_' + str(i)] = data[reg] - data[reg].shift(i)\n",
    "        X_fields.add('ph_' + str(i))\n",
    "      \n",
    "    for i in xrange(1, 3):\n",
    "        value['pd_' + str(i)] = data[reg] - data[reg].shift(24*i)\n",
    "        X_fields.add('pd_' + str(i))\n",
    "\n",
    "    value['sum_p_12_h'] = [value['count'][i-12:i].sum() for i in xrange(data.shape[0])]\n",
    "    value['sum_p_24_h'] = [value['count'][i-24:i].sum() for i in xrange(data.shape[0])]\n",
    "    value['sum_p_w'] = [value['count'][i-24*7:i].sum() for i in xrange(data.shape[0])]\n",
    "    \n",
    "    # Добавляем целевые значения для каждой из 6 можделей\n",
    "    for i in xrange(1, 7):\n",
    "        value['target_' + str(i)] = data[reg].shift(-i)\n",
    "        y_fields.add('target_' + str(i))\n",
    "        \n",
    "    values = values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>region</th>\n",
       "      <th>datetime</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>ph_1</th>\n",
       "      <th>ph_2</th>\n",
       "      <th>ph_3</th>\n",
       "      <th>...</th>\n",
       "      <th>pd_2</th>\n",
       "      <th>sum_p_12_h</th>\n",
       "      <th>sum_p_24_h</th>\n",
       "      <th>sum_p_w</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "      <th>target_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  region            datetime  day  month  weekday  hour  ph_1  ph_2  \\\n",
       "0     80    1075 2016-01-01 00:00:00    1      1        4     0   NaN   NaN   \n",
       "1     91    1075 2016-01-01 01:00:00    1      1        4     1  11.0   NaN   \n",
       "2     90    1075 2016-01-01 02:00:00    1      1        4     2  -1.0  10.0   \n",
       "3     32    1075 2016-01-01 03:00:00    1      1        4     3 -58.0 -59.0   \n",
       "4     24    1075 2016-01-01 04:00:00    1      1        4     4  -8.0 -66.0   \n",
       "\n",
       "   ph_3    ...     pd_2  sum_p_12_h  sum_p_24_h  sum_p_w  target_1  target_2  \\\n",
       "0   NaN    ...      NaN           0           0        0      91.0      90.0   \n",
       "1   NaN    ...      NaN           0           0        0      90.0      32.0   \n",
       "2   NaN    ...      NaN           0           0        0      32.0      24.0   \n",
       "3 -48.0    ...      NaN           0           0        0      24.0      11.0   \n",
       "4 -67.0    ...      NaN           0           0        0      11.0       7.0   \n",
       "\n",
       "   target_3  target_4  target_5  target_6  \n",
       "0      32.0      24.0      11.0       7.0  \n",
       "1      24.0      11.0       7.0       9.0  \n",
       "2      11.0       7.0       9.0      18.0  \n",
       "3       7.0       9.0      18.0      22.0  \n",
       "4       9.0      18.0      22.0      27.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(5, 100, 5)\n",
    "topModels = {}\n",
    "topAlphas = {}\n",
    "\n",
    "X_fields = list(X_fields)\n",
    "y_fields = list(y_fields)\n",
    "\n",
    "models = dict()\n",
    "\n",
    "# Для каждой модели на данных до апреля включительно подберём параметр альфа\n",
    "for i in xrange(1, 7):\n",
    "    best_model, best_alpha, best_mae = None, None, float('inf')\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        model = Lasso(alpha=alpha)\n",
    "        \n",
    "        train = values[(values.datetime >= train_from) & (values.datetime <= train_to)]\n",
    "        test = values[(values.datetime >= test_from) & (values.datetime <= test_to)]\n",
    "        \n",
    "\n",
    "        model_fitted = model.fit(train[X_fields].values, train['target_' + str(i)].values)\n",
    "        predict = model_fitted.predict(test[X_fields].values)\n",
    "        mae = mean_absolute_error(test['target_' + str(i)], predict)\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model_fitted\n",
    "            best_alpha = alpha\n",
    "            \n",
    "    models[i] = (best_model, best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(1, 7):\n",
    "    best_model, best_alpha, best_mae = None, None, float('inf')\n",
    "    alpha = models[i][1]\n",
    "    \n",
    "    for a in xrange(alpha if alpha == 5 else alpha - 4, alpha + 5):\n",
    "        model = Lasso(alpha=a)\n",
    "        \n",
    "        train = values[(values.datetime >= train_from) & (values.datetime <= train_to)]\n",
    "        test = values[(values.datetime >= test_from) & (values.datetime <= test_to)]\n",
    "        \n",
    "\n",
    "        model_fitted = model.fit(train[X_fields].values, train['target_' + str(i)].values)\n",
    "        predict = model_fitted.predict(test[X_fields].values)\n",
    "        mae = mean_absolute_error(test['target_' + str(i)], predict)\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model_fitted\n",
    "            best_alpha = alpha\n",
    "            \n",
    "    models[i] = (best_model, best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (Lasso(alpha=5, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False), 5),\n",
       " 2: (Lasso(alpha=5, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False), 5),\n",
       " 3: (Lasso(alpha=9, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False), 10),\n",
       " 4: (Lasso(alpha=13, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False), 15),\n",
       " 5: (Lasso(alpha=15, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False), 15),\n",
       " 6: (Lasso(alpha=25, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False), 25)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.8420381038\n"
     ]
    }
   ],
   "source": [
    "_from = pd.to_datetime('2016-04-30 23:00:00')\n",
    "\n",
    "total_mae = 0\n",
    "for region in region_list:\n",
    "    mae = 0  \n",
    "    items = values[values['region'] == region]\n",
    "    \n",
    "    for j in range(0, 739):\n",
    "        pred_datetime = _from + timedelta(hours=j)\n",
    "        current_data = items[items['datetime'] == pred_datetime]\n",
    "        \n",
    "        mae += np.sum(\n",
    "            mean_absolute_error(current_data['target_' + str(i)], models[i][0].predict(current_data[X_fields]))\n",
    "            for i in range(1, 7)\n",
    "        )\n",
    "    total_mae += mae\n",
    "    \n",
    "print total_mae / (102 * 739 * 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготавливаем данные предсказаний прошлой недели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('region_count.csv', index_col=0)\n",
    "data.datetime = data.datetime.map(lambda x: pd.to_datetime(x))\n",
    "\n",
    "count_models = 6\n",
    "\n",
    "train_from = pd.to_datetime('2016-02-01 00:00:00')\n",
    "train_to = pd.to_datetime('2016-04-30 17:00:00')\n",
    "\n",
    "test_from = pd.to_datetime('2016-04-30 23:00:00')\n",
    "test_to = pd.to_datetime('2016-05-31 17:00:00')\n",
    "\n",
    "data = data[data.datetime >= train_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('results_5.csv')\n",
    "pred['region'] = pred.id.map(lambda x: int(x.split('_')[0]))\n",
    "pred['date'] = pred.id.map(lambda x: x.split('_')[1])\n",
    "pred['hour'] = pred.id.map(lambda x: int(x.split('_')[2]))\n",
    "pred['pred_id'] = pred.id.map(lambda x: int(x.split('_')[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>pred_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1075_2016-02-01_0_1</td>\n",
       "      <td>12.495022</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075_2016-02-01_0_2</td>\n",
       "      <td>13.330542</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1075_2016-02-01_0_3</td>\n",
       "      <td>16.492265</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1075_2016-02-01_0_4</td>\n",
       "      <td>18.102986</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075_2016-02-01_0_5</td>\n",
       "      <td>16.997692</td>\n",
       "      <td>1075</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id          y  region        date  hour  pred_id\n",
       "0  1075_2016-02-01_0_1  12.495022    1075  2016-02-01     0        1\n",
       "1  1075_2016-02-01_0_2  13.330542    1075  2016-02-01     0        2\n",
       "2  1075_2016-02-01_0_3  16.492265    1075  2016-02-01     0        3\n",
       "3  1075_2016-02-01_0_4  18.102986    1075  2016-02-01     0        4\n",
       "4  1075_2016-02-01_0_5  16.997692    1075  2016-02-01     0        5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = [\n",
    "    (2014, 1, 1), (2014, 1, 20), (2014, 3, 17), (2014, 4, 20), (2014, 5, 26), \n",
    "    (2014, 7, 4), (2014, 9, 1), (2014, 10, 13), (2014, 11, 11), (2014, 11, 27), (2014, 12, 25),\n",
    "    \n",
    "    (2015, 1, 1), (2015, 1, 19), (2015, 3, 17), (2015, 4, 5), (2015, 5, 25),\n",
    "    (2015, 7, 4), (2015, 9, 7), (2015, 10, 12), (2015, 11, 11), (2015, 11, 26), (2015, 12, 25),\n",
    "    \n",
    "    (2016, 1, 1), (2016, 1, 18), (2016, 3, 17), (2016, 3, 27), (2016, 5, 30), (2016, 7, 4)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём набор признаков. Как оказалось увеличение периода данныхдля обучения моделей слабо влияет на качество предсказания. Добавлены признаки предсказаний полученных ранее, праздников, дат, времени, средней длительности и протяженности поездки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fields = {'count', 'region', 'year', 'day', 'month', 'weekday', 'hour', 'holiday', 'distance', 'time', 'sum_p_6_h', 'sum_p_12_h', 'sum_p_24_h', 'sum_p_w'}\n",
    "y_fields = set()\n",
    "values = pd.DataFrame()\n",
    "for region in region_list:\n",
    "    item = data[data.region == region].sort_values('datetime')\n",
    "    pred_items = pred[pred.region == region]\n",
    "\n",
    "    # Добавляем признаки дня, месяца, дня недели и часа.\n",
    "    item['day'] = item.datetime.map(lambda x: x.day)\n",
    "    item['month'] = item.datetime.map(lambda x: x.month)\n",
    "    item['weekday'] = item.datetime.map(lambda x: x.weekday())\n",
    "    item['hour'] = item.datetime.map(lambda x: x.hour)\n",
    "    item['year'] = item.datetime.map(lambda x: x.year)\n",
    "    \n",
    "    for i in xrange(1, count_models+1):\n",
    "        item['pred_' + str(i)] = item.datetime.map(\n",
    "            lambda x: \n",
    "            pred_items[\n",
    "                (pred_items.date == str(x.date())) & \n",
    "                (pred_items.hour == x.hour) &\n",
    "                (pred_items.pred_id == i)\n",
    "            ].y.values[0]\n",
    "            if pred_items[\n",
    "                (pred_items.date == str(x.date())) & \n",
    "                (pred_items.hour == x.hour) &\n",
    "                (pred_items.pred_id == i)\n",
    "            ].shape[0]\n",
    "            else 0\n",
    "        )\n",
    "        X_fields.add('pred_' + str(i))\n",
    "        \n",
    "    # Добавляем признаки праздничных дней и выходных дней\n",
    "    item['holiday'] = item.datetime.map(lambda x: int((x.year, x.month, x.day) in holidays))\n",
    "    \n",
    "    for i in xrange(1, 24):\n",
    "        item['ph_' + str(i)] = item['count'] - item['count'].shift(i)\n",
    "        X_fields.add('ph_' + str(i))\n",
    "\n",
    "    for i in xrange(1, 7):\n",
    "        item['pd_' + str(i)] = item['count'] - item['count'].shift(24*i)\n",
    "        X_fields.add('pd_' + str(i))\n",
    "\n",
    "    item['sum_p_6_h'] = [item['count'][i-6:i].sum() for i in xrange(item.shape[0])]\n",
    "    item['sum_p_12_h'] = [item['count'][i-12:i].sum() for i in xrange(item.shape[0])]\n",
    "    item['sum_p_24_h'] = [item['count'][i-24:i].sum() for i in xrange(item.shape[0])]\n",
    "    item['sum_p_w'] = [item['count'][i-24*7:i].sum() for i in xrange(item.shape[0])]\n",
    "    \n",
    "    # Добавляем целевые значения для каждой из 6 можделей\n",
    "    for i in xrange(1, count_models+1):\n",
    "        item['target_' + str(i)] = item['count'].shift(-i)\n",
    "        y_fields.add('target_' + str(i))\n",
    "    \n",
    "    values = values.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "values = values.fillna(0)\n",
    "values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбираем значения параметра alpha для каждой из моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(5, 100, 5)\n",
    "\n",
    "X_fields = list(X_fields)\n",
    "y_fields = list(y_fields)\n",
    "\n",
    "models = dict()\n",
    "train = values[(values.datetime >= train_from) & (values.datetime <= train_to)]\n",
    "test = values[(values.datetime >= test_from) & (values.datetime <= test_to)]\n",
    "\n",
    "# Для каждой модели на данных до апреля включительно подберём параметр альфа\n",
    "for i in xrange(1, count_models+1):\n",
    "    best_model, best_alpha, best_mae = None, None, float('inf')\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        model = Lasso(alpha=alpha)\n",
    "\n",
    "        model_fitted = model.fit(train[X_fields].values, train['target_' + str(i)].values)\n",
    "        predict = model_fitted.predict(test[X_fields].values)\n",
    "        mae = mean_absolute_error(test['target_' + str(i)], predict)\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model_fitted\n",
    "            best_alpha = alpha\n",
    "            \n",
    "    models[i] = (best_model, best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уточняем значение alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(1, count_models+1):\n",
    "    best_model, best_alpha, best_mae = None, None, float('inf')\n",
    "    alpha = models[i][1]\n",
    "    \n",
    "    for a in xrange(alpha if alpha == 5 else alpha - 4, alpha + 5):\n",
    "        model = Lasso(alpha=a)\n",
    "\n",
    "        model_fitted = model.fit(train[X_fields].values, train['target_' + str(i)].values)\n",
    "        predict = model_fitted.predict(test[X_fields].values)\n",
    "        mae = mean_absolute_error(test['target_' + str(i)], predict)\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model_fitted\n",
    "            best_alpha = alpha\n",
    "            \n",
    "    models[i] = (best_model, best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранными моделями построим для каждой географической зоны и каждого конца истории от 2016.04.30 23:00 до 2016.05.31 17:00 прогнозы на 6 часов вперёд; посчитайте в ноутбуке ошибку прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_from = pd.to_datetime('2016-04-30 23:00:00')\n",
    "\n",
    "total_mae = 0\n",
    "for region in region_list:\n",
    "    mae = 0  \n",
    "    items = values[values['region'] == region].sort_values('datetime')\n",
    "    \n",
    "    for j in range(0, 739):\n",
    "        pred_datetime = _from + timedelta(hours=j)\n",
    "        current_data = items[items['datetime'] == pred_datetime]\n",
    "        \n",
    "        mae += np.sum(\n",
    "            mean_absolute_error(current_data['target_' + str(i)], models[i][0].predict(current_data[X_fields]))\n",
    "            for i in range(1, count_models+1)\n",
    "        )\n",
    "    total_mae += mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print total_mae / (102 * 739 * count_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка с прошлой недели слабо уменьшилась. Попробуем на этих же данных использовать ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём оптимальные значения параметров n_estimators для каждой из моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_models = dict()\n",
    "for i in xrange(1, count_models+1):\n",
    "    best_model, best_alpha, best_mae = None, None, float('inf')\n",
    "    for j in range(5, 100, 5):\n",
    "        etr = ExtraTreesRegressor(n_estimators=j)\n",
    "        etr_model = etr.fit(train[X_fields].values, train['target_' + str(i)].values)\n",
    "        predict = etr_model.predict(test[X_fields].values)\n",
    "        mae = mean_absolute_error(test['target_' + str(i)], predict)\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = etr_model\n",
    "            best_estimators = j\n",
    "            \n",
    "    etr_models[i] = (best_model, best_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уточним значения n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xrange(1, count_models+1):\n",
    "    best_model, best_estimators, best_mae = None, None, float('inf')\n",
    "    estimators = etr_models[i][1]\n",
    "    \n",
    "    for a in xrange(estimators if estimators == 5 else estimators - 4, estimators + 5):\n",
    "        etr = ExtraTreesRegressor(n_estimators=a)\n",
    "\n",
    "        etr_fitted = etr.fit(train[X_fields].values, train['target_' + str(i)].values)\n",
    "        predict = etr_fitted.predict(test[X_fields].values)\n",
    "        mae = mean_absolute_error(test['target_' + str(i)], predict)\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = etr_fitted\n",
    "            best_estimators = a\n",
    "            \n",
    "    etr_models[i] = (best_model, best_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранными моделями построим для каждой географической зоны и каждого конца истории от 2016.04.30 23:00 до 2016.05.31 17:00 прогнозы на 6 часов вперёд; посчитайте в ноутбуке ошибку прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_from = pd.to_datetime('2016-04-30 23:00:00')\n",
    "\n",
    "total_mae = 0\n",
    "for region in region_list:\n",
    "    mae = 0  \n",
    "    items = values[values['region'] == region].sort_values('datetime')\n",
    "    \n",
    "    for j in range(0, 739):\n",
    "        pred_datetime = _from + timedelta(hours=j)\n",
    "        current_data = items[items['datetime'] == pred_datetime]\n",
    "        \n",
    "        mae += np.sum(\n",
    "            mean_absolute_error(current_data['target_' + str(i)], etr_models[i][0].predict(current_data[X_fields]))\n",
    "            for i in range(1, count_models + 1)\n",
    "        )\n",
    "    total_mae += mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print total_mae / (102 * 739 * count_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало сильно лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговыми моделями постройте прогнозы для каждого конца истории от 2016.05.31 23:00 до 2016.06.30 17:00 и запишите все результаты в один файл в формате geoID, histEndDay, histEndHour, step, y. Здесь geoID — идентификатор зоны, histEndDay — день конца истории в формате id,y, где столбец id состоит из склеенных через подчёркивание идентификатора географической зоны, даты конца истории, часа конца истории и номера отсчёта, на который делается предсказание (1-6); столбец y — ваш прогноз.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_from = pd.to_datetime('2016-05-31 23:00:00')\n",
    "models = etr_models\n",
    "\n",
    "results = open('results.csv', 'w')\n",
    "results.write('id,y\\n')\n",
    "for region in region_list:\n",
    "    mae = 0  \n",
    "    items = values[values['region'] == region]\n",
    "    \n",
    "    for j in range(0, 715):\n",
    "        pred_datetime = _from + timedelta(hours=j)\n",
    "        current_data = items[items['datetime'] == pred_datetime]\n",
    "        \n",
    "        for i in range(1, count_models+1):\n",
    "            predict = models[i][0].predict(current_data[X_fields])\n",
    "            results.write('{}_{}_{}_{},{}\\n'.format(region, pred_datetime.date(), pred_datetime.hour, i, predict[0]))\n",
    "    \n",
    "results.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мой результат: https://yadi.sk/i/uBbV4X113YD8iN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
